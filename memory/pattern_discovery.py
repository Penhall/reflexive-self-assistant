# memory/pattern_discovery.py
"""
Sistema de Descoberta de Padr√µes - Identifica padr√µes emergentes nas experi√™ncias
Integra com sistema simb√≥lico atual para manter compatibilidade
"""

import yaml
import json
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from collections import Counter, defaultdict
from sklearn.cluster import DBSCAN
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

from memory.hybrid_store import GraphRAGMemoryStore # Alterado de HybridMemoryStore
from config.paths import IDENTITY_STATE # Removido SYMBOLIC_TIMELINE, MEMORY_LOG

@dataclass
class DiscoveredPattern:
    """Padr√£o descoberto pelo sistema"""
    id: str
    name: str
    description: str
    template: str
    success_rate: float
    usage_count: int
    contexts: List[str]
    quality_impact: float
    discovery_date: datetime
    related_experiences: List[str]
    confidence_score: float


class PatternDiscoveryEngine:
    """
    Engine para descoberta autom√°tica de padr√µes de codifica√ß√£o
    """
    
    def __init__(self, memory_store: GraphRAGMemoryStore): # Alterado de HybridMemoryStore
        self.memory = memory_store
        self.vectorizer = TfidfVectorizer(
            max_features=1000,
            stop_words='english',
            ngram_range=(1, 3)
        )
        self.discovered_patterns = []
        self.pattern_evolution = {}
        
    def discover_patterns(self, min_occurrences: int = 3, 
                         min_success_rate: float = 0.7) -> List[DiscoveredPattern]:
        """
        Descobre padr√µes emergentes nas experi√™ncias armazenadas
        """
        print("üîç Iniciando descoberta de padr√µes...")
        
        # 1. Coletar experi√™ncias recentes
        experiences = self._collect_recent_experiences()
        if len(experiences) < min_occurrences:
            print(f"‚ö†Ô∏è Poucas experi√™ncias ({len(experiences)}) para descobrir padr√µes")
            return []
        
        # 2. An√°lise de clustering por similaridade
        code_clusters = self._cluster_by_code_similarity(experiences)
        
        # 3. An√°lise de padr√µes por dom√≠nio/tarefa  
        task_patterns = self._analyze_task_patterns(experiences)
        
        # 4. An√°lise de qualidade vs abordagem
        quality_patterns = self._analyze_quality_patterns(experiences)
        
        # 5. Combinar e validar padr√µes
        all_patterns = code_clusters + task_patterns + quality_patterns
        validated_patterns = self._validate_patterns(all_patterns, min_occurrences, min_success_rate)
        
        # 6. Atualizar padr√µes conhecidos
        self._update_pattern_evolution(validated_patterns)
        
        # 7. Integrar com sistema simb√≥lico atual - CORRIGIDO
        self._integrate_with_symbolic_system(validated_patterns)
        
        self.discovered_patterns = validated_patterns
        print(f"‚úÖ {len(validated_patterns)} padr√µes descobertos")
        
        return validated_patterns
    
    def _collect_recent_experiences(self, days_ago: int = 30) -> List[Dict]:
        """Coleta experi√™ncias recentes do GraphRAG"""
        experiences = []
        
        try:
            # Experi√™ncias do GraphRAG
            if self.memory: # Verificar se a mem√≥ria est√° inicializada
                with self.memory.neo4j.session() as session:
                    result = session.run("""
                        MATCH (e:Experience)-[:GENERATED_CODE]->(c:Code)
                        WHERE e.timestamp > datetime() - duration('P30D')
                        RETURN e, c
                        ORDER BY e.timestamp DESC
                        LIMIT 100
                    """)
                    
                    for record in result:
                        exp = record['e']
                        code = record['c']
                        experiences.append({
                            'id': exp['id'],
                            'task': exp['task_description'],
                            'code': code['content'],
                            'quality': exp['quality_score'], 
                            'success': exp['execution_success'],
                            'agent': exp['agent_name'],
                            'timestamp': exp['timestamp'],
                            'source': 'graphrag'
                        })
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao coletar experi√™ncias do GraphRAG: {e}")
        
        return experiences
    
    # Removido _extract_yaml_experiences
    
    def _cluster_by_code_similarity(self, experiences: List[Dict]) -> List[DiscoveredPattern]:
        """Agrupa experi√™ncias por similaridade de c√≥digo"""
        patterns = []
        
        try:
            # Extrair c√≥digos v√°lidos
            codes = [exp['code'] for exp in experiences if exp.get('code') and len(exp['code'].strip()) > 20]
            
            if len(codes) < 3:
                return patterns
            
            # Vetorizar c√≥digos
            code_vectors = self.vectorizer.fit_transform(codes)
            
            # Clustering DBSCAN
            clustering = DBSCAN(eps=0.3, min_samples=2, metric='cosine')
            clusters = clustering.fit_predict(code_vectors.toarray())
            
            # Processar cada cluster
            cluster_groups = defaultdict(list)
            for i, cluster_id in enumerate(clusters):
                if cluster_id != -1:  # Ignorar outliers
                    cluster_groups[cluster_id].append(i)
            
            for cluster_id, indices in cluster_groups.items():
                if len(indices) >= 2:  # M√≠nimo 2 experi√™ncias similares
                    cluster_experiences = [experiences[codes.index(experiences[i]['code'])] for i in indices]
                    pattern = self._extract_code_pattern(cluster_experiences, f"code_cluster_{cluster_id}")
                    if pattern:
                        patterns.append(pattern)
                        
        except Exception as e:
            print(f"‚ö†Ô∏è Erro no clustering de c√≥digo: {e}")
        
        return patterns
    
    def _extract_code_pattern(self, similar_experiences: List[Dict], pattern_id: str) -> Optional[DiscoveredPattern]:
        """Extrai padr√£o comum de experi√™ncias similares"""
        try:
            # Calcular m√©tricas do padr√£o
            success_rate = sum(1 for exp in similar_experiences if exp.get('success', False)) / len(similar_experiences)
            avg_quality = sum(exp.get('quality', 0) for exp in similar_experiences) / len(similar_experiences)
            
            # Extrair caracter√≠sticas comuns
            codes = [exp.get('code', '') for exp in similar_experiences]
            tasks = [exp.get('task', '') for exp in similar_experiences]
            
            # Identificar template comum
            template = self._find_common_code_structure(codes)
            
            # Identificar contextos
            contexts = list(set([self._extract_context(task) for task in tasks]))
            
            # Gerar descri√ß√£o
            description = self._generate_pattern_description(template, contexts, similar_experiences)
            
            return DiscoveredPattern(
                id=pattern_id,
                name=f"Padr√£o de {contexts[0] if contexts else 'C√≥digo'}",
                description=description,
                template=template,
                success_rate=success_rate,
                usage_count=len(similar_experiences),
                contexts=contexts,
                quality_impact=avg_quality,
                discovery_date=datetime.now(),
                related_experiences=[exp.get('id', '') for exp in similar_experiences],
                confidence_score=min(success_rate + (len(similar_experiences) / 10), 1.0)
            )
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao extrair padr√£o: {e}")
            return None
    
    def _find_common_code_structure(self, codes: List[str]) -> str:
        """Encontra estrutura comum entre c√≥digos"""
        if not codes:
            return ""
        
        # An√°lise simples de estruturas comuns
        common_patterns = []
        
        # Verificar padr√µes de fun√ß√£o
        if all('def ' in code for code in codes):
            common_patterns.append("def {function_name}({parameters}):")
        
        # Verificar padr√µes de valida√ß√£o
        if any(pattern in ' '.join(codes).lower() for pattern in ['if not', 'raise', 'assert']):
            common_patterns.append("    # Valida√ß√£o de entrada")
        
        # Verificar padr√µes de retorno
        if all('return' in code for code in codes):
            common_patterns.append("    return {result}")
        
        # Verificar padr√µes de erro
        if any('try:' in code for code in codes):
            common_patterns.append("    # Tratamento de erro")
        
        template = '\n'.join(common_patterns) if common_patterns else codes[0][:100] + "..."
        return template
    
    def _analyze_task_patterns(self, experiences: List[Dict]) -> List[DiscoveredPattern]:
        """Analisa padr√µes por tipo de tarefa"""
        patterns = []
        
        try:
            # Agrupar por dom√≠nio de tarefa
            task_groups = defaultdict(list)
            
            for exp in experiences:
                domain = self._extract_context(exp.get('task', ''))
                task_groups[domain].append(exp)
            
            # Analisar cada grupo
            for domain, group_experiences in task_groups.items():
                if len(group_experiences) >= 3:  # M√≠nimo 3 experi√™ncias por dom√≠nio
                    pattern = self._create_task_pattern(domain, group_experiences)
                    if pattern:
                        patterns.append(pattern)
                        
        except Exception as e:
            print(f"‚ö†Ô∏è Erro na an√°lise de padr√µes de tarefa: {e}")
        
        return patterns
    
    def _create_task_pattern(self, domain: str, experiences: List[Dict]) -> Optional[DiscoveredPattern]:
        """Cria padr√£o baseado em dom√≠nio de tarefa"""
        try:
            # Calcular m√©tricas
            success_rate = sum(1 for exp in experiences if exp.get('success', False)) / len(experiences)
            avg_quality = sum(exp.get('quality', 0) for exp in experiences) / len(experiences)
            
            # Identificar abordagens bem-sucedidas
            successful_approaches = [
                exp for exp in experiences 
                if exp.get('success', False) and exp.get('quality', 0) >= 7.0
            ]
            
            if not successful_approaches:
                return None
            
            # Extrair template de abordagem
            best_approach = max(successful_approaches, key=lambda x: x.get('quality', 0))
            template = best_approach.get('code', '')[:200] + "..." if len(best_approach.get('code', '')) > 200 else best_approach.get('code', '')
            
            # Gerar descri√ß√£o
            description = f"Padr√£o para tarefas de {domain}: abordagem bem-sucedida em {len(successful_approaches)}/{len(experiences)} casos"
            
            return DiscoveredPattern(
                id=f"task_pattern_{domain}",
                name=f"Padr√£o {domain.title()}",
                description=description,
                template=template,
                success_rate=success_rate,
                usage_count=len(experiences),
                contexts=[domain],
                quality_impact=avg_quality,
                discovery_date=datetime.now(),
                related_experiences=[exp.get('id', '') for exp in experiences],
                confidence_score=min(success_rate * (len(successful_approaches) / len(experiences)), 1.0)
            )
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao criar padr√£o de tarefa: {e}")
            return None
    
    def _analyze_quality_patterns(self, experiences: List[Dict]) -> List[DiscoveredPattern]:
        """Analisa padr√µes que levam a alta qualidade"""
        patterns = []
        
        try:
            # Dividir em alta e baixa qualidade
            high_quality = [exp for exp in experiences if exp.get('quality', 0) >= 8.0]
            low_quality = [exp for exp in experiences if exp.get('quality', 0) < 6.0]
            
            if len(high_quality) < 3:
                return patterns
            
            # Analisar caracter√≠sticas de alta qualidade
            hq_codes = [exp.get('code', '') for exp in high_quality]
            lq_codes = [exp.get('code', '') for exp in low_quality]
            
            # Encontrar elementos que aparecem mais em alta qualidade
            quality_indicators = self._find_quality_indicators(hq_codes, lq_codes)
            
            if quality_indicators:
                pattern = DiscoveredPattern(
                    id="quality_pattern_high",
                    name="Padr√£o de Alta Qualidade",
                    description=f"Elementos que aumentam qualidade: {', '.join(quality_indicators)}",
                    template=f"# Incluir: {', '.join(quality_indicators)}",
                    success_rate=1.0,
                    usage_count=len(high_quality),
                    contexts=["quality_improvement"],
                    quality_impact=sum(exp.get('quality', 0) for exp in high_quality) / len(high_quality),
                    discovery_date=datetime.now(),
                    related_experiences=[exp.get('id', '') for exp in high_quality],
                    confidence_score=len(high_quality) / len(experiences)
                )
                patterns.append(pattern)
                
        except Exception as e:
            print(f"‚ö†Ô∏è Erro na an√°lise de padr√µes de qualidade: {e}")
        
        return patterns
    
    def _find_quality_indicators(self, high_quality_codes: List[str], low_quality_codes: List[str]) -> List[str]:
        """Encontra elementos que indicam alta qualidade"""
        indicators = []
        
        # Elementos a verificar
        quality_elements = [
            ('docstrings', ['"""', "'''"]),
            ('error_handling', ['try:', 'except:', 'raise']),
            ('validation', ['if not', 'assert', 'validate']),
            ('comments', ['#']),
            ('type_hints', [': str', ': int', ': float', ': bool', '->'])
        ]
        
        hq_text = ' '.join(high_quality_codes).lower()
        lq_text = ' '.join(low_quality_codes).lower() if low_quality_codes else ''
        
        for element_name, keywords in quality_elements:
            hq_count = sum(hq_text.count(keyword) for keyword in keywords)
            lq_count = sum(lq_text.count(keyword) for keyword in keywords) if lq_text else 0
            
            # Se aparece mais em alta qualidade
            if hq_count > lq_count * 1.5:  # 50% mais frequente
                indicators.append(element_name)
        
        return indicators
    
    def _validate_patterns(self, patterns: List[DiscoveredPattern], 
                          min_occurrences: int, min_success_rate: float) -> List[DiscoveredPattern]:
        """Valida e filtra padr√µes descobertos"""
        validated = []
        
        for pattern in patterns:
            if (pattern.usage_count >= min_occurrences and 
                pattern.success_rate >= min_success_rate and
                pattern.confidence_score >= 0.5):
                validated.append(pattern)
        
        # Ordenar por confian√ßa
        validated.sort(key=lambda p: p.confidence_score, reverse=True)
        
        return validated
    
    def _update_pattern_evolution(self, new_patterns: List[DiscoveredPattern]):
        """Atualiza evolu√ß√£o dos padr√µes ao longo do tempo"""
        timestamp = datetime.now().isoformat()
        
        for pattern in new_patterns:
            if pattern.id not in self.pattern_evolution:
                self.pattern_evolution[pattern.id] = []
            
            self.pattern_evolution[pattern.id].append({
                'timestamp': timestamp,
                'usage_count': pattern.usage_count,
                'success_rate': pattern.success_rate,
                'quality_impact': pattern.quality_impact,
                'confidence_score': pattern.confidence_score
            })
    
    def _integrate_with_symbolic_system(self, patterns: List[DiscoveredPattern]):
        """
        CORRIGIDO: Integra padr√µes descobertos com sistema simb√≥lico atual
        Garante cria√ß√£o de symbolic_traits e mapeamento robusto
        """
        try:
            # Carregar estado simb√≥lico atual
            with open(IDENTITY_STATE, 'r', encoding='utf-8') as f:
                identity_data = yaml.safe_load(f) or {}
            
            # CORRE√á√ÉO: Adicionar insights de padr√µes aos agentes
            for agent_name in identity_data.keys():
                if agent_name not in identity_data:
                    continue
                
                agent_data = identity_data[agent_name]
                
                # CORRE√á√ÉO: Garantir que symbolic_traits existe SEMPRE
                if 'symbolic_traits' not in agent_data:
                    agent_data['symbolic_traits'] = []
                
                # Adicionar padr√µes relevantes
                relevant_patterns = [
                    p for p in patterns 
                    if p.success_rate > 0.8 and p.confidence_score > 0.7
                ]
                
                if relevant_patterns:
                    if 'discovered_patterns' not in agent_data:
                        agent_data['discovered_patterns'] = []
                    
                    for pattern in relevant_patterns[:3]:  # Top 3 padr√µes
                        agent_data['discovered_patterns'].append({
                            'name': pattern.name,
                            'success_rate': pattern.success_rate,
                            'contexts': pattern.contexts,
                            'discovery_date': pattern.discovery_date.isoformat()
                        })
                    
                    # CORRE√á√ÉO: Mapeamento robusto de padr√µes para traits simb√≥licos
                    new_traits = self._map_patterns_to_traits(relevant_patterns)
                    
                    # Adicionar novos traits √∫nicos
                    existing_traits = set(agent_data.get('traits', []))
                    existing_symbolic_traits = set(agent_data.get('symbolic_traits', []))
                    
                    for trait in new_traits:
                        # Adicionar a traits normais se n√£o existir
                        if trait not in existing_traits:
                            if 'traits' not in agent_data:
                                agent_data['traits'] = []
                            agent_data['traits'].append(trait)
                            existing_traits.add(trait)
                        
                        # Adicionar a symbolic_traits se n√£o existir
                        if trait not in existing_symbolic_traits:
                            agent_data['symbolic_traits'].append(trait)
                            existing_symbolic_traits.add(trait)
            
            # Salvar estado atualizado
            with open(IDENTITY_STATE, 'w', encoding='utf-8') as f:
                yaml.safe_dump(identity_data, f, allow_unicode=True, sort_keys=False)
            
            print(f"üîó {len(patterns)} padr√µes integrados ao sistema simb√≥lico")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erro na integra√ß√£o simb√≥lica: {e}")
    
    def _map_patterns_to_traits(self, patterns: List[DiscoveredPattern]) -> List[str]:
        """
        NOVO: Mapeia padr√µes descobertos para traits simb√≥licos
        """
        traits = []
        
        for pattern in patterns:
            pattern_name_lower = pattern.name.lower()
            pattern_desc_lower = pattern.description.lower()
            contexts = [ctx.lower() for ctx in pattern.contexts]
            
            # Mapeamento baseado no nome do padr√£o
            if 'qualidade' in pattern_name_lower or 'quality' in pattern_name_lower:
                traits.append('Qualidade-Orientado')
            
            if 'valida√ß√£o' in pattern_name_lower or 'validation' in pattern_name_lower:
                traits.append('Validador')
            
            if 'seguran√ßa' in pattern_name_lower or 'security' in pattern_name_lower:
                traits.append('Seguran√ßa-Consciente')
            
            if 'performance' in pattern_name_lower or 'otimiza√ß√£o' in pattern_name_lower:
                traits.append('Performance-Otimizado')
            
            # Mapeamento baseado no contexto
            if 'authentication' in contexts:
                traits.append('Especialista-Auth')
            
            if 'api_development' in contexts:
                traits.append('API-Developer')
            
            if 'database' in contexts:
                traits.append('Data-Handler')
            
            if 'testing' in contexts:
                traits.append('Test-Driven')
            
            # Mapeamento baseado na descri√ß√£o
            if 'error' in pattern_desc_lower or 'exception' in pattern_desc_lower:
                traits.append('Error-Handler')
            
            if 'docstring' in pattern_desc_lower or 'documentation' in pattern_desc_lower:
                traits.append('Documentador')
            
            # Mapeamento baseado na taxa de sucesso
            if pattern.success_rate >= 0.95:
                traits.append('Altamente-Confi√°vel')
            elif pattern.success_rate >= 0.85:
                traits.append('Confi√°vel')
            
            # Mapeamento baseado no impacto na qualidade
            if pattern.quality_impact >= 9.0:
                traits.append('Excellence-Seeker')
            elif pattern.quality_impact >= 8.0:
                traits.append('Quality-Focused')
        
        # Remover duplicatas e retornar
        return list(set(traits))
    
    def _extract_context(self, task: str) -> str:
        """Extrai contexto/dom√≠nio da tarefa"""
        task_lower = task.lower()
        
        if any(word in task_lower for word in ['login', 'auth', 'password', 'user']):
            return 'authentication'
        elif any(word in task_lower for word in ['api', 'endpoint', 'rest', 'http']):
            return 'api_development'
        elif any(word in task_lower for word in ['database', 'db', 'sql', 'query']):
            return 'database'
        elif any(word in task_lower for word in ['test', 'verify', 'check']):
            return 'testing'
        elif any(word in task_lower for word in ['file', 'read', 'write', 'csv']):
            return 'file_processing'
        elif any(word in task_lower for word in ['soma', 'calc', 'math', 'number']):
            return 'mathematical'
        else:
            return 'general'
    
    def _generate_pattern_description(self, template: str, contexts: List[str], 
                                    experiences: List[Dict]) -> str:
        """Gera descri√ß√£o humana do padr√£o"""
        context_str = ', '.join(contexts) if contexts else 'geral'
        success_count = sum(1 for exp in experiences if exp.get('success', False))
        
        return f"Padr√£o comum para {context_str}: usado em {len(experiences)} casos, {success_count} sucessos"
    
    def get_pattern_recommendations(self, current_task: str) -> List[Dict[str, Any]]:
        """Retorna recomenda√ß√µes de padr√µes para tarefa atual"""
        if not self.discovered_patterns:
            return []
        
        task_context = self._extract_context(current_task)
        recommendations = []
        
        for pattern in self.discovered_patterns:
            if (task_context in pattern.contexts or 
                'general' in pattern.contexts or
                pattern.success_rate > 0.9):
                
                relevance_score = self._calculate_relevance(pattern, current_task, task_context)
                
                recommendations.append({
                    'pattern': pattern,
                    'relevance_score': relevance_score,
                    'recommendation': self._generate_recommendation_text(pattern, current_task)
                })
        
        # Ordenar por relev√¢ncia
        recommendations.sort(key=lambda x: x['relevance_score'], reverse=True)
        
        return recommendations[:5]  # Top 5 recomenda√ß√µes
    
    def _calculate_relevance(self, pattern: DiscoveredPattern, task: str, context: str) -> float:
        """Calcula relev√¢ncia do padr√£o para a tarefa"""
        score = 0.0
        
        # Contexto matching
        if context in pattern.contexts:
            score += 0.4
        
        # Success rate
        score += pattern.success_rate * 0.3
        
        # Quality impact
        score += (pattern.quality_impact / 10.0) * 0.2
        
        # Confidence
        score += pattern.confidence_score * 0.1
        
        return min(score, 1.0)
    
    def _generate_recommendation_text(self, pattern: DiscoveredPattern, task: str) -> str:
        """Gera texto de recomenda√ß√£o para o padr√£o"""
        return f"Considere usar o padr√£o '{pattern.name}' (taxa de sucesso: {pattern.success_rate:.1%}, qualidade m√©dia: {pattern.quality_impact:.1f})"
    
    def export_patterns_summary(self) -> Dict[str, Any]:
        """Exporta resumo dos padr√µes para dashboard"""
        return {
            'total_patterns': len(self.discovered_patterns),
            'patterns': [
                {
                    'id': p.id,
                    'name': p.name,
                    'description': p.description,
                    'success_rate': p.success_rate,
                    'usage_count': p.usage_count,
                    'quality_impact': p.quality_impact,
                    'contexts': p.contexts,
                    'confidence_score': p.confidence_score,
                    'discovery_date': p.discovery_date.isoformat()
                }
                for p in self.discovered_patterns
            ],
            'pattern_evolution': self.pattern_evolution,
            'summary_stats': {
                'avg_success_rate': sum(p.success_rate for p in self.discovered_patterns) / len(self.discovered_patterns) if self.discovered_patterns else 0,
                'total_experiences_analyzed': sum(p.usage_count for p in self.discovered_patterns),
                'high_confidence_patterns': len([p for p in self.discovered_patterns if p.confidence_score > 0.8])
            }
        }


# Scheduler para execu√ß√£o autom√°tica (mantido inalterado)
import threading
import time

class PatternDiscoveryScheduler:
    """Scheduler para executar descoberta de padr√µes automaticamente"""
    
    def __init__(self, discovery_engine: PatternDiscoveryEngine, 
                 interval_hours: int = 24):
        self.engine = discovery_engine
        self.interval_hours = interval_hours
        self.running = False
        self.thread = None
    
    def start(self):
        """Inicia execu√ß√£o autom√°tica"""
        if not self.running:
            self.running = True
            self.thread = threading.Thread(target=self._run_discovery_loop)
            self.thread.daemon = True
            self.thread.start()
            print(f"üîÑ Pattern Discovery agendado a cada {self.interval_hours}h")
    
    def stop(self):
        """Para execu√ß√£o autom√°tica"""
        self.running = False
        if self.thread:
            self.thread.join()
        print("‚èπÔ∏è Pattern Discovery interrompido")
    
    def _run_discovery_loop(self):
        """Loop principal de descoberta"""
        while self.running:
            try:
                print("üïê Executando descoberta autom√°tica de padr√µes...")
                patterns = self.engine.discover_patterns()
                print(f"‚úÖ Descoberta conclu√≠da: {len(patterns)} padr√µes")
                
            except Exception as e:
                print(f"‚ùå Erro na descoberta autom√°tica: {e}")
            
            # Aguardar pr√≥xima execu√ß√£o
            time.sleep(self.interval_hours * 3600)


# Exemplo de uso (mantido inalterado)
if __name__ == "__main__":
    # Inicializar sistema
    memory_store = GraphRAGMemoryStore() # Alterado de HybridMemoryStore
    discovery_engine = PatternDiscoveryEngine(memory_store)
    
    # Descobrir padr√µes
    patterns = discovery_engine.discover_patterns()
    
    print(f"\nüìä RESUMO DOS PADR√ïES DESCOBERTOS:")
    print(f"Total: {len(patterns)}")
    
    for pattern in patterns:
        print(f"\nüîπ {pattern.name}")
        print(f"   Descri√ß√£o: {pattern.description}")
        print(f"   Taxa de sucesso: {pattern.success_rate:.1%}")
        print(f"   Impacto na qualidade: {pattern.quality_impact:.1f}")
        print(f"   Confian√ßa: {pattern.confidence_score:.1%}")
    
    # Testar recomenda√ß√µes
    print(f"\nüí° RECOMENDA√á√ïES PARA 'criar fun√ß√£o de login':")
    recommendations = discovery_engine.get_pattern_recommendations("criar fun√ß√£o de login")
    
    for rec in recommendations:
        print(f"   ‚Ä¢ {rec['recommendation']} (Relev√¢ncia: {rec['relevance_score']:.1%})")
    
    # Exportar resumo
    summary = discovery_engine.export_patterns_summary()
    print(f"\nüìà ESTAT√çSTICAS:")
    print(f"   Padr√µes de alta confian√ßa: {summary['summary_stats']['high_confidence_patterns']}")
    print(f"   Taxa m√©dia de sucesso: {summary['summary_stats']['avg_success_rate']:.1%}")
    
    memory_store.close()
