#!/usr/bin/env python3
"""
Limpeza de modelos grandes do Ollama - vers√£o Python multiplataforma
Substitui cleanup_large_models.sh para funcionar no Windows
"""

import requests
import subprocess
import sys
import time
from typing import List, Dict, Tuple
from datetime import datetime

class ModelCleaner:
    def __init__(self):
        self.ollama_host = "http://localhost:11434"
        self.timeout = 30
        
        # Modelos grandes para remo√ß√£o (usar RAM excessiva)
        self.large_models_to_remove = [
            "llama3:8b", "llama3:15b", "llama3:70b",
            "codellama:7b", "codellama:13b", "codellama:34b", 
            "mistral:7b", "mistral:15b",
            "mixtral:8x7b", "mixtral:8x22b",
            "llama2:7b", "llama2:13b", "llama2:70b",
            "vicuna:7b", "vicuna:13b", "vicuna:33b",
            "orca-mini:7b", "orca-mini:13b",
            "wizardcoder:7b", "wizardcoder:13b", "wizardcoder:34b",
            "deepseek-coder:6.7b", "deepseek-coder:33b",
            "openchat:7b", "starling-lm:7b",
            "yi:6b", "yi:34b",
            "solar:10.7b", "dolphin-mixtral:8x7b"
        ]
        
        # Modelos leves recomendados (manter)
        self.recommended_lightweight = [
            "tinyllama:1.1b",    # ~800MB - Ultra leve
            "llama3.2:1b",       # ~1GB - Novo e eficiente  
            "codegemma:2b",      # ~1.5GB - Especializado em c√≥digo
            "phi3:mini",         # ~2GB - Equilibrado
            "qwen2:0.5b",        # ~500MB - Ultra compacto
            "qwen2:1.5b",        # ~1GB - Bom custo-benef√≠cio
            "gemma:2b"           # ~1.5GB - Desenvolvido pelo Google
        ]
        
        self.stats = {
            "removed": 0,
            "kept": 0,
            "errors": 0,
            "space_freed": "Unknown"
        }
    
    def check_ollama_available(self) -> bool:
        """Verifica se Ollama est√° dispon√≠vel"""
        print("üîç Verificando se Ollama est√° rodando...")
        
        try:
            response = requests.get(f"{self.ollama_host}/api/tags", timeout=5)
            if response.status_code == 200:
                print("‚úÖ Ollama est√° rodando!")
                return True
            else:
                print(f"‚ùå Ollama retornou status {response.status_code}")
                return False
        except requests.exceptions.RequestException as e:
            print(f"‚ùå Erro de conex√£o com Ollama: {e}")
            print("üí° Certifique-se de que Ollama est√° rodando:")
            print("   ‚Ä¢ Docker: docker-compose up -d")
            print("   ‚Ä¢ Local: ollama serve")
            return False
    
    def list_installed_models(self) -> List[Dict]:
        """Lista modelos instalados"""
        try:
            response = requests.get(f"{self.ollama_host}/api/tags", timeout=10)
            if response.status_code == 200:
                data = response.json()
                return data.get("models", [])
            else:
                print(f"‚ùå Erro ao listar modelos: HTTP {response.status_code}")
                return []
        except Exception as e:
            print(f"‚ùå Erro ao listar modelos: {e}")
            return []
    
    def remove_model(self, model_name: str) -> bool:
        """Remove um modelo espec√≠fico"""
        try:
            # Usar subprocess para chamada direta ao ollama
            result = subprocess.run(
                ["ollama", "rm", model_name],
                capture_output=True,
                text=True,
                timeout=self.timeout
            )
            
            if result.returncode == 0:
                return True
            else:
                print(f"      ‚ö†Ô∏è Erro ao remover {model_name}: {result.stderr}")
                return False
                
        except subprocess.TimeoutExpired:
            print(f"      ‚ö†Ô∏è Timeout ao remover {model_name}")
            return False
        except FileNotFoundError:
            print("      ‚ùå Comando 'ollama' n√£o encontrado")
            print("      üí° Certifique-se de que Ollama est√° instalado e no PATH")
            return False
        except Exception as e:
            print(f"      ‚ö†Ô∏è Erro ao remover {model_name}: {e}")
            return False
    
    def estimate_model_size(self, model_info: Dict) -> str:
        """Estima tamanho do modelo baseado no nome"""
        name = model_info.get("name", "").lower()
        
        # Estimativas baseadas no tamanho do modelo
        if "70b" in name or "72b" in name:
            return "~40GB"
        elif any(size in name for size in ["33b", "34b"]):
            return "~20GB"  
        elif any(size in name for size in ["13b", "15b"]):
            return "~8GB"
        elif any(size in name for size in ["7b", "8b"]):
            return "~4GB"
        elif "2b" in name:
            return "~1.5GB"
        elif "1b" in name:
            return "~800MB"
        elif "0.5b" in name or "mini" in name:
            return "~500MB"
        else:
            # Tentar obter do campo size se dispon√≠vel
            return model_info.get("size", "Unknown")
    
    def analyze_and_remove_large_models(self):
        """Analisa e remove modelos grandes"""
        print("\nüîç ANALISANDO MODELOS INSTALADOS")
        print("-" * 50)
        
        installed_models = self.list_installed_models()
        if not installed_models:
            print("‚ùå Nenhum modelo encontrado ou erro na listagem")
            return False
        
        print(f"üì¶ {len(installed_models)} modelos instalados:")
        for model in installed_models:
            name = model.get("name", "unknown")
            size = self.estimate_model_size(model)
            print(f"   ‚Ä¢ {name} ({size})")
        
        print(f"\nüóëÔ∏è REMOVENDO MODELOS GRANDES:")
        print("-" * 30)
        
        removed_models = []
        for model_name in self.large_models_to_remove:
            # Verificar se modelo est√° instalado
            is_installed = any(
                model.get("name") == model_name 
                for model in installed_models
            )
            
            if is_installed:
                print(f"   üóëÔ∏è Removendo {model_name}...")
                
                # Mostrar tamanho estimado
                matching_model = next(
                    (m for m in installed_models if m.get("name") == model_name), 
                    {}
                )
                size = self.estimate_model_size(matching_model)
                print(f"      Liberando {size} de espa√ßo...")
                
                if self.remove_model(model_name):
                    print(f"      ‚úÖ {model_name} removido com sucesso")
                    removed_models.append(model_name)
                    self.stats["removed"] += 1
                else:
                    print(f"      ‚ùå Falha ao remover {model_name}")
                    self.stats["errors"] += 1
        
        print(f"\nüìä Resumo da remo√ß√£o:")
        print(f"   üóëÔ∏è Modelos removidos: {len(removed_models)}")
        if removed_models:
            for model in removed_models:
                print(f"      ‚Ä¢ {model}")
        
        return len(removed_models) > 0
    
    def check_recommended_models(self):
        """Verifica se modelos recomendados est√£o instalados"""
        print(f"\n‚úÖ VERIFICANDO MODELOS RECOMENDADOS")
        print("-" * 40)
        
        installed_models = self.list_installed_models()
        installed_names = [model.get("name") for model in installed_models]
        
        present_models = []
        missing_models = []
        
        for model in self.recommended_lightweight:
            if model in installed_names:
                matching_model = next(
                    (m for m in installed_models if m.get("name") == model), 
                    {}
                )
                size = self.estimate_model_size(matching_model)
                print(f"   ‚úÖ {model} ({size}) - Instalado")
                present_models.append(model)
                self.stats["kept"] += 1
            else:
                print(f"   ‚ö†Ô∏è {model} - N√£o instalado (recomendado)")
                missing_models.append(model)
        
        print(f"\nüìä Status dos modelos recomendados:")
        print(f"   ‚úÖ Presentes: {len(present_models)}/{len(self.recommended_lightweight)}")
        print(f"   ‚ö†Ô∏è Ausentes: {len(missing_models)}")
        
        if missing_models:
            print(f"\nüí° MODELOS RECOMENDADOS PARA INSTALAR:")
            for model in missing_models:
                specialty = self.get_model_specialty(model)
                print(f"   üì• ollama pull {model}  # {specialty}")
        
        return present_models, missing_models
    
    def get_model_specialty(self, model_name: str) -> str:
        """Retorna especialidade do modelo"""
        specialties = {
            "tinyllama:1.1b": "Ultra-leve, ideal para testes",
            "llama3.2:1b": "Novo modelo compacto da Meta",
            "codegemma:2b": "Especializado em c√≥digo",
            "phi3:mini": "Equilibrado para uso geral",
            "qwen2:0.5b": "Ultra-compacto da Alibaba",
            "qwen2:1.5b": "Eficiente para tarefas variadas",
            "gemma:2b": "Modelo leve do Google"
        }
        return specialties.get(model_name, "Modelo leve recomendado")
    
    def show_installation_guide(self, missing_models: List[str]):
        """Mostra guia de instala√ß√£o para modelos faltantes"""
        if not missing_models:
            return
        
        print(f"\nüöÄ GUIA DE INSTALA√á√ÉO R√ÅPIDA")
        print("-" * 35)
        
        print("Instalar todos os modelos recomendados:")
        print("```bash")
        for model in missing_models:
            print(f"ollama pull {model}")
        print("```")
        
        print(f"\nOu instalar apenas os essenciais:")
        essentials = ["codegemma:2b", "tinyllama:1.1b"]
        for model in essentials:
            if model in missing_models:
                specialty = self.get_model_specialty(model)
                print(f"ollama pull {model}  # {specialty}")
    
    def calculate_benefits(self):
        """Calcula benef√≠cios da limpeza"""
        print(f"\nüß† BENEF√çCIOS DA LIMPEZA")
        print("-" * 25)
        
        if self.stats["removed"] > 0:
            print("‚ú® Melhorias obtidas:")
            print(f"   üíæ Espa√ßo liberado: ~{self.stats['removed'] * 5}GB estimados")
            print(f"   üêè RAM liberada: ~{self.stats['removed'] * 4}GB por execu√ß√£o")
            print("   ‚ö° Velocidade: Modelos leves respondem 3-5x mais r√°pido")
            print("   üîÑ Estabilidade: Menor chance de timeout/out-of-memory")
            print("   üéØ Foco: Otimiza√ß√£o para desenvolvimento com modelos eficientes")
        else:
            print("‚ÑπÔ∏è Nenhum modelo grande foi removido")
            print("   Isso pode significar que:")
            print("   ‚Ä¢ Sistema j√° est√° otimizado")
            print("   ‚Ä¢ Modelos grandes n√£o estavam instalados")
    
    def show_next_steps(self, missing_models: List[str]):
        """Mostra pr√≥ximos passos recomendados"""
        print(f"\n‚ö° PR√ìXIMOS PASSOS")
        print("-" * 18)
        
        if missing_models:
            print("1. üì• Instalar modelos recomendados:")
            print(f"   python scripts/config/install_models.py")
            print()
        
        print("2. üß™ Testar sistema:")
        print("   python scripts/tests/test_system.py")
        print()
        
        print("3. üöÄ Executar RSCA:")
        print("   python core/main.py")
        print()
        
        print("4. üìä Dashboard (opcional):")
        print("   streamlit run interface/dashboard/streamlit_app.py")
    
    def run_cleanup(self):
        """Executa limpeza completa"""
        print("üßπ LIMPEZA DE MODELOS GRANDES - RSCA")
        print("=" * 50)
        print(f"üïí {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # Verificar se Ollama est√° dispon√≠vel
        if not self.check_ollama_available():
            return False
        
        # Mostrar modelos atuais
        installed_models = self.list_installed_models()
        if not installed_models:
            print("‚ùå N√£o foi poss√≠vel listar modelos")
            return False
        
        # Executar limpeza
        print(f"\nüéØ Iniciando limpeza de {len(self.large_models_to_remove)} modelos grandes conhecidos...")
        cleanup_success = self.analyze_and_remove_large_models()
        
        # Verificar modelos recomendados
        present_models, missing_models = self.check_recommended_models()
        
        # Calcular benef√≠cios
        self.calculate_benefits()
        
        # Mostrar pr√≥ximos passos
        self.show_next_steps(missing_models)
        
        # Resumo final
        print(f"\n" + "=" * 50)
        print("üìã RESUMO DA LIMPEZA")
        print("=" * 50)
        
        print(f"üóëÔ∏è Modelos removidos: {self.stats['removed']}")
        print(f"‚úÖ Modelos leves presentes: {self.stats['kept']}")
        print(f"‚ùå Erros: {self.stats['errors']}")
        print(f"‚ö†Ô∏è Modelos recomendados ausentes: {len(missing_models)}")
        
        if self.stats["removed"] > 0 or self.stats["kept"] > 0:
            print(f"\n‚ú® Limpeza conclu√≠da com sucesso!")
            if missing_models:
                print(f"üí° Considere instalar os modelos recomendados ausentes")
        else:
            print(f"\n‚ö†Ô∏è Nenhuma altera√ß√£o realizada")
            print("   Sistema pode j√° estar otimizado ou sem modelos grandes")
        
        return True

def main():
    if len(sys.argv) > 1:
        if sys.argv[1] == "--help":
            print("Limpeza de modelos grandes do Ollama")
            print("\nUso: python scripts/config/cleanup_models.py [op√ß√µes]")
            print("\nOp√ß√µes:")
            print("  --help     Mostra esta ajuda")
            print("  --dry-run  Simula limpeza sem remover modelos")
            print("\nEste script:")
            print("  ‚Ä¢ Remove modelos grandes (7B+) que consomem muita RAM")
            print("  ‚Ä¢ Mant√©m modelos leves (‚â§2B) otimizados para desenvolvimento")
            print("  ‚Ä¢ Mostra recomenda√ß√µes de modelos ausentes")
            print("  ‚Ä¢ Calcula benef√≠cios da limpeza")
            sys.exit(0)
        elif sys.argv[1] == "--dry-run":
            print("üîç MODO SIMULA√á√ÉO - Nenhum modelo ser√° removido")
            print("-" * 45)
            # Implementar dry-run seria interessante, mas n√£o √© cr√≠tico
    
    cleaner = ModelCleaner()
    success = cleaner.run_cleanup()
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()